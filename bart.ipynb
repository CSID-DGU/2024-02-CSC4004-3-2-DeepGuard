{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2024-02-CSC4004-3-2-DeepGuard/blob/dev_jb/bart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiOaqyEkoQ9s",
        "outputId": "91f30a62-f8dd-4c74-e5d1-7e2da5f4329e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wWzceZepP-Z"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t-_0ADuun3Th"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # for array\n",
        "import pandas as pd  # for csv files and dataframe\n",
        "import matplotlib.pyplot as plt  # for plotting\n",
        "import seaborn as sns  # plotting\n",
        "from scipy import stats\n",
        "\n",
        "import pickle  # To load data int disk\n",
        "from prettytable import PrettyTable  # To print in tabular format\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer\n",
        "from sklearn.metrics import auc, f1_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_validate, cross_val_predict\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DWHYSU2piSJ"
      },
      "source": [
        "# Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TIUuRRx6piCM"
      },
      "outputs": [],
      "source": [
        "# Creating a empty dict, where I will save all parameters required for test data transformation\n",
        "\n",
        "saved_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eVREmHCppokU"
      },
      "outputs": [],
      "source": [
        "# Reading datasets\n",
        "dfs = []\n",
        "for i in range(1,5):\n",
        "    path = '/content/UNSW_NB15_training-set.csv'  # There are 4 input csv files\n",
        "    dfs.append(pd.read_csv(path.format(i), header = None))\n",
        "all_data = pd.concat(dfs).reset_index(drop=True)  # Concat all to a single df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Bb37z-Aspod3"
      },
      "outputs": [],
      "source": [
        "# This csv file contains names of all the features\n",
        "df_col = pd.read_csv('/content/NUSW-NB15_features.csv', encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sfnP54UYpoaH"
      },
      "outputs": [],
      "source": [
        "# Making column names lower case, removing spaces\n",
        "df_col['Name'] = df_col['Name'].apply(lambda x: x.strip().replace(' ', '').lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "k0yuUeF7poT6"
      },
      "outputs": [],
      "source": [
        "# Renaming our dataframe with proper column names\n",
        "all_data.columns = df_col['Name'][:45]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2qsb3Egnpgqr"
      },
      "outputs": [],
      "source": [
        "# Saving useful info, later this will be used to transform raw test data\n",
        "saved_dict['columns'] = df_col['Name'][df_col['Name']!='label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9rF0CUi4pwN5"
      },
      "outputs": [],
      "source": [
        "del df_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPtzi4WzpwIR",
        "outputId": "1ae1b798-1b81-484b-fc1b-1998313b77ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(329332, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "all_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "1dIsyUmjpu3a",
        "outputId": "848fbe79-d61b-498a-c9f8-c3eb75479a30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name srcip     sport  dstip   dsport  proto  state    dur  sbytes  dbytes  \\\n",
              "0       id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes   \n",
              "1        1  0.000011    udp        -    INT      2      0     496       0   \n",
              "2        2  0.000008    udp        -    INT      2      0    1762       0   \n",
              "3        3  0.000005    udp        -    INT      2      0    1068       0   \n",
              "4        4  0.000006    udp        -    INT      2      0     900       0   \n",
              "\n",
              "Name         sttl  ...   is_sm_ips_ports    ct_state_ttl ct_flw_http_mthd  \\\n",
              "0            rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm     is_ftp_login   \n",
              "1      90909.0902  ...                 1               2                0   \n",
              "2     125000.0003  ...                 1               2                0   \n",
              "3     200000.0051  ...                 1               3                0   \n",
              "4     166666.6608  ...                 1               3                0   \n",
              "\n",
              "Name is_ftp_login        ct_ftp_cmd  ct_srv_src  ct_srv_dst       ct_dst_ltm  \\\n",
              "0      ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports   \n",
              "1               0                 0           1           2                0   \n",
              "2               0                 0           1           2                0   \n",
              "3               0                 0           1           3                0   \n",
              "4               0                 0           2           3                0   \n",
              "\n",
              "Name  ct_src_ltm ct_src_dport_ltm  \n",
              "0     attack_cat            label  \n",
              "1         Normal                0  \n",
              "2         Normal                0  \n",
              "3         Normal                0  \n",
              "4         Normal                0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e05b767b-4e7f-4890-9db2-0ea74aca8be5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Name</th>\n",
              "      <th>srcip</th>\n",
              "      <th>sport</th>\n",
              "      <th>dstip</th>\n",
              "      <th>dsport</th>\n",
              "      <th>proto</th>\n",
              "      <th>state</th>\n",
              "      <th>dur</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>sttl</th>\n",
              "      <th>...</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>ct_state_ttl</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_srv_src</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>ct_dst_ltm</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_src_dport_ltm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>dur</td>\n",
              "      <td>proto</td>\n",
              "      <td>service</td>\n",
              "      <td>state</td>\n",
              "      <td>spkts</td>\n",
              "      <td>dpkts</td>\n",
              "      <td>sbytes</td>\n",
              "      <td>dbytes</td>\n",
              "      <td>rate</td>\n",
              "      <td>...</td>\n",
              "      <td>ct_dst_sport_ltm</td>\n",
              "      <td>ct_dst_src_ltm</td>\n",
              "      <td>is_ftp_login</td>\n",
              "      <td>ct_ftp_cmd</td>\n",
              "      <td>ct_flw_http_mthd</td>\n",
              "      <td>ct_src_ltm</td>\n",
              "      <td>ct_srv_dst</td>\n",
              "      <td>is_sm_ips_ports</td>\n",
              "      <td>attack_cat</td>\n",
              "      <td>label</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>496</td>\n",
              "      <td>0</td>\n",
              "      <td>90909.0902</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1762</td>\n",
              "      <td>0</td>\n",
              "      <td>125000.0003</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1068</td>\n",
              "      <td>0</td>\n",
              "      <td>200000.0051</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>900</td>\n",
              "      <td>0</td>\n",
              "      <td>166666.6608</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e05b767b-4e7f-4890-9db2-0ea74aca8be5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e05b767b-4e7f-4890-9db2-0ea74aca8be5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e05b767b-4e7f-4890-9db2-0ea74aca8be5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0d6f1c2-763c-4946-8952-ddd1e5bf76b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0d6f1c2-763c-4946-8952-ddd1e5bf76b3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0d6f1c2-763c-4946-8952-ddd1e5bf76b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_data"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "all_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3P5PkHZsL7M"
      },
      "source": [
        "# 데이터 로드 및 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbC5hXWyq8J_",
        "outputId": "f884b3a4-d93d-423f-fb59-59193920f07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:\n",
            "0        1 1.1e-05 udp - INT 2 0 496 0 90909.0902 254 0...\n",
            "1        2 8e-06 udp - INT 2 0 1762 0 125000.0003 254 0...\n",
            "2        3 5e-06 udp - INT 2 0 1068 0 200000.0051 254 0...\n",
            "3        4 6e-06 udp - INT 2 0 900 0 166666.6608 254 0 ...\n",
            "4        5 1e-05 udp - INT 2 0 2126 0 100000.0025 254 0...\n",
            "                               ...                        \n",
            "82327    82328 5e-06 udp - INT 2 0 104 0 200000.0051 25...\n",
            "82328    82329 1.106101 tcp - FIN 20 8 18062 354 24.410...\n",
            "82329    82330 0.0 arp - INT 1 0 46 0 0.0 0 0 0.0 0.0 0...\n",
            "82330    82331 0.0 arp - INT 1 0 46 0 0.0 0 0 0.0 0.0 0...\n",
            "82331    82332 9e-06 udp - INT 2 0 104 0 111111.1072 25...\n",
            "Length: 82332, dtype: object\n",
            "Training set size: 74098\n",
            "Test set size: 8234\n"
          ]
        }
      ],
      "source": [
        "path = '/content/UNSW_NB15_training-set.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# 각 행의 모든 열 데이터를 공백으로 구분된 문자열로 변환\n",
        "train_data = df.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "\n",
        "# 변환된 데이터 출력\n",
        "print(\"Train Data:\")\n",
        "print(train_data)\n",
        "\n",
        "# 파일로 저장하고 싶은 경우\n",
        "train_data.to_csv('train_data.csv', index=False, header=False)\n",
        "\n",
        "if 'text' not in df.columns:\n",
        "    df['text'] = df.iloc[:,0]\n",
        "#데이터 분리\n",
        "X = df['text']\n",
        "if 'attack_cat' in df.columns:\n",
        "    y = df['attack_cat']\n",
        "else:\n",
        "  y = pd.Series([0] * len(df), index=df.index)\n",
        "\n",
        "  # 데이터셋을 훈련 세트와 테스트 세트로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "#데이터 분리\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Test set size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq7KxYEVsi_H"
      },
      "source": [
        "# 분류기 설정 및 학습"
      ]
    },
    {
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load the BART tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-base\", num_labels=len(y.unique()))\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "def batch_tokenize(text_list, batch_size=32):\n",
        "    encodings = {'input_ids': [], 'attention_mask': []}\n",
        "    for i in range(0, len(text_list), batch_size):\n",
        "        # Convert batch elements to strings before tokenization\n",
        "        batch = [str(text) for text in text_list[i:i+batch_size]]\n",
        "        batch_encodings = tokenizer(\n",
        "            batch, truncation=True, padding='max_length', max_length=128)\n",
        "        encodings['input_ids'].extend(batch_encodings['input_ids'])\n",
        "        encodings['attention_mask'].extend(batch_encodings['attention_mask'])\n",
        "    return encodings\n",
        "\n",
        "train_encodings = batch_tokenize(X_train.tolist(), batch_size=batch_size)\n",
        "test_encodings = batch_tokenize(X_test.tolist(), batch_size=batch_size)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ-g5rTzF8Su",
        "outputId": "6147d484-4969-4cce-d86e-cf6034fddf03"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "weRYCwUqk2Kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab16aa2-6829-4721-bc3a-0689e6c8bbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Train dataset size: 74098\n",
            "Test dataset size: 8234\n",
            "\n",
            "Sample from the test dataset:\n",
            "{'input_ids': tensor([    0,  3170, 29312,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(6)}\n",
            "{'input_ids': tensor([   0,  245, 4027, 5606,    2,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(5)}\n",
            "{'input_ids': tensor([    0,  1549, 28497,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(5)}\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers torch datasets\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Prepare dataset class\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        if isinstance(labels[0], str):\n",
        "            self.label_encoder = LabelEncoder()\n",
        "            self.labels = self.label_encoder.fit_transform(labels)\n",
        "        else:\n",
        "            self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = Dataset(train_encodings, y_train.tolist())\n",
        "test_dataset = Dataset(test_encodings, y_test.tolist())\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "print(\"\\nSample from the test dataset:\")\n",
        "for i in range(3):\n",
        "    print(test_dataset[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7DtrmDQ6gxUm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "f7a7c0be-77dc-4f06-b283-a7aeb25902f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [348/348 5:50:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.812082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.730211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.696690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=348, training_loss=0.9528066700902479, metrics={'train_runtime': 21067.512, 'train_samples_per_second': 2.11, 'train_steps_per_second': 0.017, 'total_flos': 3408808843464192.0, 'train_loss': 0.9528066700902479, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "!pip install transformers\n",
        "\n",
        "import wandb\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "import random\n",
        "!pip install wandb -qqq\n",
        "!pip install transformers\n",
        "\n",
        "import wandb\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "sample_size = int(len(train_dataset) * 0.2) #Corrected line\n",
        "random_indices = random.sample(range(len(train_dataset)), sample_size)\n",
        "train_dataset = Subset(train_dataset, random_indices)\n",
        "\n",
        "# Initialize Trainer with optimized settings\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model using the test dataset\n",
        "test_results = trainer.evaluate()\n",
        "\n",
        "# 3. 예측 진행 및 결과 확인\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Extract predictions based on the structure of PredictionOutput\n",
        "logits = predictions.predictions[0]  # Assuming predictions is a tuple and the first element is the logits/probabilities\n",
        "\n",
        "# Check shape and content of logits\n",
        "print(\"Shape of logits:\", logits.shape)\n",
        "print(\"First few elements of logits:\", logits[:5])\n",
        "\n",
        "# Try to adapt predictions based on the model's actual output:\n",
        "# If the output contains generated text, process it for classification first.\n",
        "# For example, if it outputs probabilities for each class:\n",
        "\n",
        "# pred_labels = np.argmax(logits, axis=-1) # original line\n",
        "try:\n",
        "    pred_labels = np.argmax(logits, axis=-1) # 예측된 라벨\n",
        "except ValueError:\n",
        "    print(\"Predictions are not in expected format. Attempting to fix...\")\n",
        "    # Assuming you get probabilities in logits:\n",
        "    # Reshape to (num_samples, num_classes) if necessary\n",
        "    num_samples = logits.shape[0]\n",
        "    num_classes = model.config.num_labels\n",
        "    if logits.shape != (num_samples, num_classes):\n",
        "        logits = logits.reshape(num_samples, num_classes)\n",
        "    pred_labels = np.argmax(logits, axis=-1) # 예측된 라벨\n",
        "\n",
        "true_labels = predictions.label_ids  # 실제 라벨\n",
        "\n",
        "print(\"\\nSample of predicted labels:\")\n",
        "print(pred_labels[:10])  # 예측 라벨의 첫 10개 확인\n",
        "print(\"\\nSample of true labels:\")\n",
        "print(true_labels[:10])  # 실제 라벨의 첫 10개 확인\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 5. 분류 리포트\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, pred_labels))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "bFSnE1OPiren",
        "outputId": "302dd196-6151-48fa-df32-3a11787a9232"
      },
      "execution_count": 31,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='487' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [258/258 34:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of logits: (8234, 10)\n",
            "First few elements of logits: [[-0.9454375  -1.3200552   0.31958053  0.31029183 -0.30421838 -1.0805866\n",
            "   7.3548393  -0.50673056 -1.0897467  -2.1031249 ]\n",
            " [-0.43983078 -0.7707858  -0.03807732  1.6132381   1.5618694   2.7641957\n",
            "  -2.3768482   0.16739221 -1.4480834  -2.8260398 ]\n",
            " [-0.8856015  -1.1621583  -0.09772405 -0.25729465 -0.2759677   6.3111935\n",
            "  -1.1420863  -0.6079503  -0.8748362  -1.8644938 ]\n",
            " [-0.97672486 -1.1959221  -0.06396157  0.1391217  -0.51275593 -0.78947926\n",
            "   7.3440437  -0.33033532 -1.1158454  -2.066278  ]\n",
            " [-0.85423386 -0.9021393   2.0610964   2.9820008   0.8621483   0.22778134\n",
            "  -3.2783751   1.8100181  -1.5928679  -2.1706681 ]]\n",
            "\n",
            "Sample of predicted labels:\n",
            "[6 5 5 6 3 5 6 4 6 3]\n",
            "\n",
            "Sample of true labels:\n",
            "[6 5 5 6 3 5 6 3 6 3]\n",
            "Accuracy: 0.7490\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        65\n",
            "           1       0.00      0.00      0.00        59\n",
            "           2       0.38      0.04      0.08       398\n",
            "           3       0.45      0.49      0.47      1146\n",
            "           4       0.31      0.33      0.32       593\n",
            "           5       0.68      0.95      0.79      1907\n",
            "           6       0.98      0.98      0.98      3677\n",
            "           7       0.00      0.00      0.00       347\n",
            "           8       0.00      0.00      0.00        37\n",
            "           9       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.75      8234\n",
            "   macro avg       0.28      0.28      0.26      8234\n",
            "weighted avg       0.70      0.75      0.71      8234\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1NhPvSTtw1MUqUWYc74vW5Wd2adW_BVge",
      "authorship_tag": "ABX9TyO16uFlSo95sSQR41pTo+ob",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}